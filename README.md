# Awesom-LLM AGI Papers

Must-read Papers on Artifical General Intelligence with foundation models.

---

# üìúContent

- [Goal & Definition: The AGI we imagined](#goal--definition-the-agi-we-imagined)

- [Current state & How far?](#current-state--how-far)
  - [AGI Internal (‚ÄúBrain‚Äù)](#agi-internal-brain)
    - [Perception: multi modal (haoqin)](#perception-multi-modal-haoqin)
    - [Memory (Chuanyang, Guanyu)](#memory-chuanyang-guanyu)
      - [Short-term](#short-term)
      - [Long-term: experience, knowledge](#long-term-experience-knowledge)
    - [Reasoning (Chuanyang)](#reasoning-chuanyang)
    - [Planning (Kunlun)](#planning-kunlun)
    - [Meta-level capability](#meta-level-capability)
    - [Self-evolve (Kunlun)](#self-evolve-kunlun)
    - [Alignment capability](#alignment-capability)

- [AGI External (‚ÄúBody & World‚Äù)](#agi-external-body--world)
  - [Meta-level: How to interact with ‚ÄúTool‚Äù capability (Kunlun, Chuanyang)](#meta-level-how-to-interact-with-tool-capability-kunlun-chuanyang)
  - [With non-AI tool (with objective world) (Kunlun)](#with-non-ai-tool-with-objective-world-kunlun)
  - [With other AGI (haoqin)](#with-other-agi-haoqin)
  - [With human (Kunlun)](#with-human-kunlun)
  - [AGI Constraints/Alignment](#agi-constraintsalignment)

- [How can we get to AGI - A perspective from us](#how-can-we-get-to-agi---a-perspective-from-us)
  - [Hierarchy / levels (Kunlun, haoqin)](#hierarchy--levels-kunlun-haoqin)
  - [Evaluation (Guanyu, fengtao)](#evaluation-guanyu-fengtao)
  - [How to proceed to next level (Chuanyang)](#how-to-proceed-to-next-level-chuanyang)


# Goal & Definition: The AGI we imagined

# Current state & How far?
### AGI Internal (‚ÄúBrain‚Äù)
#### Perception: multi modal (haoqin) 
#### Memory (Chuanyang, Guanyu)
##### Short-term
##### Long-term: experience, knowledge
#### Reasoning (Chuanyang)
#### Planning (Kunlun)
1. **Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models**

   *Andy Zhou, Kai Yan, Michal Shlapentokh-Rothman, Haohan Wang, Yu-Xiong Wang.* [[abs](https://arxiv.org/abs/2310.04406)]

2. **Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents**

   *Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, Yitao Liang.* [[abs](https://arxiv.org/abs/2302.01560)]

3. **Large Language Models as Commonsense Knowledge for Large-Scale Task Planning**

   *Zirui Zhao, Wee Sun Lee, David Hsu.* [[abs](https://arxiv.org/abs/2305.14078)]

4. **Tree of thoughts: Deliberate problem solving with large language models**

   *Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, Karthik Narasimhan.* [[abs](https://arxiv.org/abs/2305.10601)]
#### Meta-level capability
#### Self-evolve (Kunlun) 
1. **Evolving Self-supervised Neural Networks Autonomous Intelligence from Evolved Self-teaching**

   *Nam Le.* [[eprint](https://arxiv.org/abs/1906.08865)]

2. **Self-Instruct: Aligning Language Models with Self-Generated Instructions**

   *Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, Hannaneh Hajishirzi.* [[eprint](https://arxiv.org/abs/2212.10560)]

3. **ReST meets ReAct: Self-Improvement for Multi-Step Reasoning LLM Agent**

   *Renat Aksitov, Sobhan Miryoosefi, Zonglin Li, Daliang Li, Sheila Babayan, Kavya Kopparapu, Zachary Fisher, Ruiqi Guo, Sushant Prakash, Pranesh Srinivasan, Manzil Zaheer, Felix Yu, Sanjiv Kumar.* [[eprint](https://arxiv.org/abs/2312.10003)]

4. **Wizardlm: Empowering large language models to follow complex instructions**

   *Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, Daxin Jiang.* [[abs](https://arxiv.org/abs/2304.12244)]

#### Alignment capability 

# AGI External (‚ÄúBody & World‚Äù)
### Meta-level: How to interact with ‚ÄúTool‚Äù capability (Kunlun, Chuanyang) 
1. **Tool learning with foundation models**

   *Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, et al.* [[abs](https://arxiv.org/abs/2304.08354)]

2. **Toolformer: Language models can teach themselves to use tools**

   *Timo Schick, Jane Dwivedi-Yu, Roberto Dess√¨, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, Thomas Scialom.* [[abs](https://arxiv.org/abs/2302.04761)]

3. **CREATOR: Disentangling Abstract and Concrete Reasonings of Large Language Models through Tool Creation**

   *Cheng Qian, Chi Han, Yi R Fung, Yujia Qin, Zhiyuan Liu, Heng Ji.* [[abs](https://arxiv.org/abs/2305.14318)]

### With non-AI tool (with objective world) (Kunlun) 
1. **Scaling up and distilling down: Language-guided robot skill acquisition**

   *Huy Ha, Pete Florence, Shuran Song.* [[abs](https://arxiv.org/abs/2307.14535)]

2. **MotionGPT: Human Motion as a Foreign Language**

   *Biao Jiang, Xin Chen, Wen Liu, Jingyi Yu, Gang Yu, Tao Chen.* [[abs](https://arxiv.org/abs/2306.14795)]

3. **Voxposer: Composable 3d value maps for robotic manipulation with language models**

   *Wenlong Huang, Chen Wang, Ruohan Zhang, Yunzhu Li, Jiajun Wu, Li Fei-Fei.* [[abs](https://arxiv.org/abs/2307.05973)]

4. **Instruct2Act: Mapping Multi-modality Instructions to Robotic Actions with Large Language Model**

   *Siyuan Huang, Zhengkai Jiang, Hao Dong, Yu Qiao, Peng Gao, Hongsheng Li.* [[abs](https://arxiv.org/abs/2305.11176)]

5. **Lm-nav: Robotic navigation with large pre-trained models of language, vision, and action**

   *Dhruv Shah, B≈Ça≈ºej Osi≈Ñski, Sergey Levine, et al.* [[abs](https://arxiv.org/abs/conference-on-robot-learning/2023/lm-nav)]
### With other AGI (haoqin)
### With human (Kunlun)
1. **The Rise of the AI Co-Pilot: Lessons for Design from Aviation and Beyond**

   *Abigail Sellen, Eric Horvitz.* [[abs](https://arxiv.org/abs/2311.14713)]

2. **Human--AI interactions in public sector decision making: ‚Äúautomation bias‚Äù and ‚Äúselective adherence‚Äù to algorithmic advice**

   *Saar Alon-Barkat, Madalina Busuioc.* Journal of Public Administration Research and Theory, Vol. 33, No. 1, pp. 153--169, 2023. Oxford University Press US.

3. **The evolution of HCI and human factors: Integrating human and artificial intelligence**

   *Mark Chignell, Lu Wang, Atefeh Zare, Jamy Li.* ACM Transactions on Computer-Human Interaction, Vol. 30, No. 2, pp. 1--30, 2023. ACM New York, NY.

4. **Human--Machine Relationship‚ÄîPerspective and Future Roadmap for Industry 5.0 Solutions**

   *Jakub Pizo≈Ñ, Arkadiusz Gola.* Machines, Vol. 11, No. 2, pp. 203, 2023. MDPI.

5. **Human-machine symbiosis: A multivariate perspective for physically coupled human-machine systems**

   *Jairo Inga, Miriam Ruess, Jan Heinrich Robens, Thomas Nelius, Simon Rothfu√ü, Sean Kille, Philipp Dahlinger, Andreas Lindenmann, Roland Thomaschke, Gerhard Neumann, et al.* International Journal of Human-Computer Studies, Vol. 170, pp. 102926, 2023. Elsevier.

### AGI Constraints/Alignment 

# How can we get to AGI - A perspective from us
## How can we get to AGI - A perspective from us
### Hierarchy / levels (Kunlun, haoqin)

### Evaluation (Guanyu, fengtao)
### AI for Science Discovery and Research (Kunlun)
1. **Benchmarking Large Language Models As AI Research Agents**

   *Qian Huang, Jian Vora, Percy Liang, Jure Leskovec.* [[abs](https://arxiv.org/abs/2310.03302)]

2. **The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4**

   *Microsoft Research AI4Science, Microsoft Azure Quantum.* [[abs](https://arxiv.org/abs/2311.07361)]

3. **Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems**

   *Stefan Kramer, Mattia Cerrato, Sa≈°o D≈æeroski, Ross King.* [[abs](https://arxiv.org/abs/2305.02251)]

4. **LLMs for Science: Usage for Code Generation and Data Analysis**

   *Mohamed Nejjar, Luca Zacharias, Fabian Stiehle, Ingo Weber.* [[abs](https://arxiv.org/abs/2311.16733)]

5. **Galactica: A large language model for science**

   *Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, Robert Stojnic.* [[abs](https://arxiv.org/abs/2211.09085)]

### How to proceed to next level (Chuanyang)




<!-- ### Agent & Tool:
- [Tool learning with foundation models](https://arxiv.org/pdf/2304.08354.pdf)
- [A Survey on Large Language Model based Autonomous Agents](https://arxiv.org/pdf/2308.11432.pdf)
- [The Rise and Potential of Large Language Model Based Agents: A Survey](https://arxiv.org/pdf/2309.07864.pdf)
- [Cognitive Architectures for Language Agents](https://arxiv.org/pdf/2309.02427.pdf)

### (Multi-Modal) LLM / Foundation Model:
#### LLM
- [A Survey of Large Language Models](https://arxiv.org/pdf/2303.18223.pdf)
- [A Survey on In-context Learning](https://arxiv.org/pdf/2301.00234.pdf)
- [Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond](https://arxiv.org/pdf/2304.13712.pdf)

#### Multi-Modal LLM
- [A Survey on Multimodal Large Language Models](https://arxiv.org/pdf/2306.13549.pdf)

#### General Foundation Model
- [On the Opportunities and Risks of Foundation Models](https://arxiv.org/pdf/2108.07258.pdf)
- [A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT](https://arxiv.org/pdf/2302.09419.pdf)

### Embodied AI:
#### AGI
- [One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era](https://arxiv.org/pdf/2304.06488.pdf)
- [Sparks of Artificial General Intelligence: Early experiments with GPT-4](https://arxiv.org/pdf/2303.12712.pdf)
- [Towards AGI in Computer Vision: Lessons Learned from GPT and Large Language Models](https://arxiv.org/pdf/2306.08641.pdf)
- [A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT](https://arxiv.org/pdf/2303.04226.pdf)

### Github:
- [LLM-Agent-Paper-List](https://github.com/WooooDyy/LLM-Agent-Paper-List) (Agent)
- [Awesome-AI-Agents](https://github.com/e2b-dev/awesome-ai-agents) (Agent)
- [Awesome-Multimodal-Large-Language-Models](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models) (Multi-modal LLM) -->
